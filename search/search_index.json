{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Calibration Service This backend service is designed to manage calibrations of a hardware device. Each calibration includes: calibration_type value timestamp username Calibrations can be tagged with arbitrary strings to describe different states of a device. Tags can be added or removed from calibrations, and the tagging history is preserved. Read full project overview Pre-requisites Python 3.12 or higher, link uv for python runtime and dependency management, link Docker Desktop or Docker Compose capable tool (e.g. podman desktop or rancher desktop ) Node.js for Pyright pre-commit hook execution, link Quick Start A) Online Deployment Live Docs - GitHub pages hosted docs site making reading these docs a bit easier ~~ Live Site - deployed application~~ # TODO: (future) (B) Offline Deployment Options Prepare Download source: Clone the repository, and go into the project directory calibration-service Avoid port conflicts: 5777 - port of dev db 5778 - port of test db 8777 - port of FastAPI web driver Troubleshooting: Verify if a local service is listening by run lsof -i :<port> to see binding. If found, pkill -9 <PID> to stop Containerized Deployment Start Docker Desktop Run Docker compose: pull images, builds, runs migrations, seeds and starts the container bash docker compose up Go to localhost:8777/docs - OpenAPI spec to explore the api (Optional) Open online documentation Note: for local deployment see DEVELOPER Cleanup bash docker compose down -v --rmi local Points of Interest OpenApi Specification Calibration Repository (Postgres) Tag Repository (Postgres) Calibration Routes (FastAPI) Tag Routes (FastAPI) Calibration Api integration tests Tagging Api integration tests Testing and validating system functionality End to End With the project up and running use docker cli to execute the e2e tests in a different terminal - test_api_use_cases_e2e.py take home assignment uc1-4 tests - test_tag_archiving_e2e.py take home assignment uc5 bash docker compose exec web uv run test_e2e Component Integration bash docker compose exec web uv run pytest tests/integration/drivers/rest bash docker compose exec web uv run pytest tests/integration/repositories Unit bash docker compose exec web uv run test Test Documentation This repository includes a comprehensive test harness following Clean Architecture principles. The testing infrastructure is designed to be expandable and maintainable. \ud83e\udde0 For detailed information about the testing approach, see docs/TESTS.md . ERD Next Steps Where I would want to continue to refine the system. Users: a users table to replace the \"username\" on a CalibrationAssociation , and allow for something to bring a trackable Actor into the system ISessions: bring Session up into the Entity layer and removing the third-party reliance on SqlAlchemy's AsyncSession IAuthentication Service: that encapsulates sign_up , sign_in , and sign_out use cases and helps demonstrate how easy swapping out one oidc provider for another could be Instrumentation/Monitoring: wrappers to monitor and benchmark each system interaction as it goes through the boundaries of the Clean Architecture surrounds all Inspiration I\u2019ve been eager to try Clean Architecture, so I was excited to take this project as a chance to dive in outside of work. In day-to-day development, we often have to stay laser-focused on shipping just enough\u2014so it was refreshing to explore a more intentional, scalable structure. I started by defining the use case and interfaces, then adapted a MongoDB repository based on shaliamekh , and later swapped in a PostgreSQL version without touching the core logic. That flexibility\u2014being able to change out infrastructure without rewriting business rules\u2014really drove home the value of this approach. Clean Architecture made it easy to innovate at the edges while keeping the core rock-solid. If you\u2019re curious about the structure, I nerded out a bit more in the ARCHITECTURE section. Developer Experience Coming from a Node.js and TypeScript background, I was initially skeptical about Python\u2014especially around tooling, type safety, and developer ergonomics. But this project turned out to be a crash course in how far the Python ecosystem has come. Tools like uv and pyproject.toml gave me the dependency management experience I\u2019d been missing, and enabling Pyright in PyCharm brought back the type hints, squiggles, and Intellisense I rely on daily. Once dialed in, my Python dev environment felt just as powerful\u2014if not more streamlined\u2014than my usual setup. On the infrastructure side, working with Terraform reminded me how much I enjoy bridging systems design with application code\u2014something I previously explored through AWS CDK. This project showed me that clean architecture, code organization, and system-level thinking (along with solid tooling habits) are transferable across languages. And in the age of AI, where every developer effectively has a supercomputer at their side, the ability to learn quickly and structure ideas well has never been more important. It\u2019s not just about syntax\u2014it\u2019s about creating an environment that helps you think clearly and ship confidently. Additional Documentation Developer Guide - Day-to-day development workflows Database Management - Detailed information about database management operations Architecture Inspiration - System design and software architecture inspiration Testing Approach - How to execute project tests and the packages used CI/CD - Description of CI/CD workflows Test Documentation This repository includes a comprehensive test harness following Clean Architecture principles. The testing infrastructure is designed to be expandable and maintainable. \ud83e\udde0 For detailed information about the testing approach, see docs/TESTS.md . Continuous Integration This project uses GitHub Actions for continuous integration and code quality checks. All workflows use uv for fast dependency resolution. Workflow Status Badge Description CI ( ci.yaml ) Full pipeline: Docker build, integration tests, and coverage reports Python Tests ( pytest.yaml ) Unit/integration tests and coverage reports Type Checking ( pyright.yaml ) Ensures type safety with Pyright Lint & Format ( ruff.yaml ) Enforces consistent style and detects common issues using Ruff \ud83e\udde0 For details, see WORKFLOWS.md .","title":"Calibration Service"},{"location":"#calibration-service","text":"This backend service is designed to manage calibrations of a hardware device. Each calibration includes: calibration_type value timestamp username Calibrations can be tagged with arbitrary strings to describe different states of a device. Tags can be added or removed from calibrations, and the tagging history is preserved. Read full project overview","title":"Calibration Service"},{"location":"#pre-requisites","text":"Python 3.12 or higher, link uv for python runtime and dependency management, link Docker Desktop or Docker Compose capable tool (e.g. podman desktop or rancher desktop ) Node.js for Pyright pre-commit hook execution, link","title":"Pre-requisites"},{"location":"#quick-start","text":"","title":"Quick Start"},{"location":"#a-online-deployment","text":"Live Docs - GitHub pages hosted docs site making reading these docs a bit easier ~~ Live Site - deployed application~~ # TODO: (future)","title":"A) Online Deployment"},{"location":"#b-offline-deployment-options","text":"","title":"(B) Offline Deployment Options"},{"location":"#prepare","text":"Download source: Clone the repository, and go into the project directory calibration-service Avoid port conflicts: 5777 - port of dev db 5778 - port of test db 8777 - port of FastAPI web driver Troubleshooting: Verify if a local service is listening by run lsof -i :<port> to see binding. If found, pkill -9 <PID> to stop","title":"Prepare"},{"location":"#containerized-deployment","text":"Start Docker Desktop Run Docker compose: pull images, builds, runs migrations, seeds and starts the container bash docker compose up Go to localhost:8777/docs - OpenAPI spec to explore the api (Optional) Open online documentation Note: for local deployment see DEVELOPER","title":"Containerized Deployment"},{"location":"#cleanup","text":"bash docker compose down -v --rmi local","title":"Cleanup"},{"location":"#points-of-interest","text":"OpenApi Specification Calibration Repository (Postgres) Tag Repository (Postgres) Calibration Routes (FastAPI) Tag Routes (FastAPI) Calibration Api integration tests Tagging Api integration tests","title":"Points of Interest"},{"location":"#testing-and-validating-system-functionality","text":"","title":"Testing and validating system functionality"},{"location":"#end-to-end","text":"With the project up and running use docker cli to execute the e2e tests in a different terminal - test_api_use_cases_e2e.py take home assignment uc1-4 tests - test_tag_archiving_e2e.py take home assignment uc5 bash docker compose exec web uv run test_e2e","title":"End to End"},{"location":"#component-integration","text":"bash docker compose exec web uv run pytest tests/integration/drivers/rest bash docker compose exec web uv run pytest tests/integration/repositories","title":"Component Integration"},{"location":"#unit","text":"bash docker compose exec web uv run test","title":"Unit"},{"location":"#test-documentation","text":"This repository includes a comprehensive test harness following Clean Architecture principles. The testing infrastructure is designed to be expandable and maintainable. \ud83e\udde0 For detailed information about the testing approach, see docs/TESTS.md .","title":"Test Documentation"},{"location":"#erd","text":"","title":"ERD"},{"location":"#next-steps","text":"Where I would want to continue to refine the system. Users: a users table to replace the \"username\" on a CalibrationAssociation , and allow for something to bring a trackable Actor into the system ISessions: bring Session up into the Entity layer and removing the third-party reliance on SqlAlchemy's AsyncSession IAuthentication Service: that encapsulates sign_up , sign_in , and sign_out use cases and helps demonstrate how easy swapping out one oidc provider for another could be Instrumentation/Monitoring: wrappers to monitor and benchmark each system interaction as it goes through the boundaries of the Clean Architecture surrounds all","title":"Next Steps"},{"location":"#inspiration","text":"I\u2019ve been eager to try Clean Architecture, so I was excited to take this project as a chance to dive in outside of work. In day-to-day development, we often have to stay laser-focused on shipping just enough\u2014so it was refreshing to explore a more intentional, scalable structure. I started by defining the use case and interfaces, then adapted a MongoDB repository based on shaliamekh , and later swapped in a PostgreSQL version without touching the core logic. That flexibility\u2014being able to change out infrastructure without rewriting business rules\u2014really drove home the value of this approach. Clean Architecture made it easy to innovate at the edges while keeping the core rock-solid. If you\u2019re curious about the structure, I nerded out a bit more in the ARCHITECTURE section.","title":"Inspiration"},{"location":"#developer-experience","text":"Coming from a Node.js and TypeScript background, I was initially skeptical about Python\u2014especially around tooling, type safety, and developer ergonomics. But this project turned out to be a crash course in how far the Python ecosystem has come. Tools like uv and pyproject.toml gave me the dependency management experience I\u2019d been missing, and enabling Pyright in PyCharm brought back the type hints, squiggles, and Intellisense I rely on daily. Once dialed in, my Python dev environment felt just as powerful\u2014if not more streamlined\u2014than my usual setup. On the infrastructure side, working with Terraform reminded me how much I enjoy bridging systems design with application code\u2014something I previously explored through AWS CDK. This project showed me that clean architecture, code organization, and system-level thinking (along with solid tooling habits) are transferable across languages. And in the age of AI, where every developer effectively has a supercomputer at their side, the ability to learn quickly and structure ideas well has never been more important. It\u2019s not just about syntax\u2014it\u2019s about creating an environment that helps you think clearly and ship confidently.","title":"Developer Experience"},{"location":"#additional-documentation","text":"Developer Guide - Day-to-day development workflows Database Management - Detailed information about database management operations Architecture Inspiration - System design and software architecture inspiration Testing Approach - How to execute project tests and the packages used CI/CD - Description of CI/CD workflows","title":"Additional Documentation"},{"location":"#test-documentation_1","text":"This repository includes a comprehensive test harness following Clean Architecture principles. The testing infrastructure is designed to be expandable and maintainable. \ud83e\udde0 For detailed information about the testing approach, see docs/TESTS.md .","title":"Test Documentation"},{"location":"#continuous-integration","text":"This project uses GitHub Actions for continuous integration and code quality checks. All workflows use uv for fast dependency resolution. Workflow Status Badge Description CI ( ci.yaml ) Full pipeline: Docker build, integration tests, and coverage reports Python Tests ( pytest.yaml ) Unit/integration tests and coverage reports Type Checking ( pyright.yaml ) Ensures type safety with Pyright Lint & Format ( ruff.yaml ) Enforces consistent style and detects common issues using Ruff \ud83e\udde0 For details, see WORKFLOWS.md .","title":"Continuous Integration"},{"location":"ARCHITECTURE/","text":"Architecture Grounding & Inspiration This project uses Clean Architecture patterns. Hereafter \"CA\" will be used for \"Clean Architecture\". Background article by Bob Martin https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html Inspiration from existing CA implementations CA with Python - by R. Shaliamekh. clean-architecture-fastapi - by shaliamekh - associated repo for blog post CA in Next.js ](https://www.youtube.com/watch?v=jJVAla0dWJo) - video describing CA nextjs-clean-architecture - by nikolovlazar - associated repo for video Other similar architectures to Clean Architecture Hexagonal Architecture - (a.k.a. Ports and Adapters) by Alistair Cockburn Onion Architecture - by Jeffrey Palermo Screaming Architecture - by Uncle Bob (the same guy behind Clean Architecture) Diagrams The CA Diagram (sphere) - by Uncle Bob - by Uncle Bob The CA Diagram (simplified) - by nikolovlazar Original \"Simplified\" Clean Architecture in Brief Great summary of how to approach these layers in-practice with the project. Note: it's heavily borrowed from nikolovlazar... thank you! Clean Architecture is a set of rules that help us structure our applications in such way that they're easier to maintain and test, and their codebases are predictable. It's like a common language that developers understand, regardless of their technical backgrounds and programming language preferences. Clean Architecture, and similar/derived architectures, all have the same goal - separation of concerns . They introduce layers that bundle similar code together. The \"layering\" helps us achieve important aspects in our codebase: Independent of UI - the business logic is not coupled with the UI framework that's being used (in this case Next.js). The same system can be used in a CLI application, without having to change the business logic or rules. Independent of Database - the database implementation/operations are isolated in their own layer, so the rest of the app does not care about which database is being used, but communicates using Models . Independent of Frameworks - the business rules and logic simply don't know anything about the outside world. They receive data defined with plain objects/dictionaries, Services and Repositories to define their own logic and functionality. This allows us to use frameworks as tools, instead of having to \"mold\" our system into their implementations and limitations. If we use Route Handlers in our app's Drivers , and want to refactor some of them to use a different framework implementation all we need to do is just invoke the specific controllers in the new framework's manner, but the core business logic remains unchanged. Testable - the business logic and rules can easily be tested because it does not depend on the UI framework, or the database, or the web server, or any other external element that builds up our system. Clean Architecture achieves this through defining a dependency hierarchy - layers depend only on layers below them , but not above. Project structure (only the important parts) app - Frameworks & Drivers Layer - basically everything Next.js (pages, server actions, components, styles etc...) or whatever \"consumes\" the app's logic ~~ di - Dependency Injection - a folder where we setup the DI container and the modules~~ # TODO: (future implementation) ~~ db - Everything DB - initializing the DB client, defining schema, migrations~~ # TODO: (future implementation) src - The \"root\" of the system application - Application Layer - holds use cases and interfaces for repositories and services entities - Entities Layer - holds models, value objects and custom errors/exceptions infrastructure - Infrastructure Layer - holds implementations of repositories and services, and pulls in the interfaces from application interface-adapters - Interface Adapters Layer - holds controllers that serve as an entry point to the system (used in Frameworks & Drivers layer to interact with the system) drivers - Frameworks & Drivers layer - holds implementation-specific details for a given framework (e.g. FastAPI routes) tests - Unit tests live here - the unit subfolder's structure matches src pyproject.toml - list of deps & configuration for python tools (linters, formatters, ) ~~Where the pylint-module-boundaries plugin is defined - this stops you from breaking the dependency rule ~~ # TODO: (future implementation) scripts - manual scripts to run project-wide actions (e.g. run tests) from bash terminal docs - project documentation .github/workflows - project cicd files Project structure (Developer Tooling) .pre-commit-config.yaml - rules triggered to run via got hooks cspell.config.yaml - custom dictionary to keep IDE's inspection pane \"clean\" .run - shared run configurations for JetBrains PyCharm IDE Layers explanation Frameworks & Drivers : keeps all the UI framework functionality, and everything else that interacts with the system (eg AWS Lambdas, Stripe webhooks etc...). In this scenario, that's FastAPI Route Handlers This layer should only use Controllers , Models , and Errors , and must not import Use Cases , Repositories , and Services . Interface Adapters : defines Controllers and Presenters : Controllers perform authentication checks and input validation before passing the input to the specific use cases. Controllers orchestrate Use Cases. They don't implement any logic, but define the whole operations using the use cases. In short, they use \"Use Case\" input ports. Errors from deeper layers are bubbled up and being handled where controllers are being used. Controllers use Presenters to convert the data to a UI-friendly format just before returning it to the \"consumer\". This helps prevent leaking any sensitive properties, like emails or hashed passwords, and also helps us slim down the amount of data we're sending back to the client. In short, they implement Use Case output ports. Application : where the business logic lives. Sometimes called core . This layer defines the Use Cases and interfaces for the services and repositories. Use Cases : Represent individual operations, like \"Create Calibration\" or \"Sign In\" Accept pre-validated input (from controllers) and handle authorization checks . Use Repositories and Services to access data sources and communicate with external systems. Use cases should not use other use cases . That's a code smell. It means the use case does multiple things and should be broken down into multiple use cases. Interfaces for Repositories and Services: These are defined in this layer because we want to break out the dependency of their tools and frameworks (database drivers, email services etc...), so we'll implement them in the Infrastructure layer. Since the interfaces live in this layer, use cases (and transitively the upper layers) can access them through Dependency Injection . Dependency Injection allows us to split up the definitions (interfaces) from the implementations (classes) and keep them in a separate layer (infrastructure), but still allow their usage. Entities : where the Models and Exceptions are defined. Models : Define \"domain\" data shapes with plain JavaScript, without using \"database\" technologies. Models are not always tied to the database - sending emails require an external email service, not a database, but we still need to have a data shape that will help other layers communicate \"sending an email\". Models also define their own validation rules, which are called \"Enterprise Business Rules\". Rules that don't usually change, or are least likely to change when something external changes (page navigation, security, etc...). An example is a User model that defines a username field that must be at least 6 characters long and not include special characters . Exceptions : We want our own errors because we don't want to be bubbling up database-specific errors, or any type of errors that are specific to a library or framework. We catch errors that are coming from other libraries (for example SQAlchemy), and convert those errors to our own errors. That's how we can keep our core independent of any frameworks, libraries, and technologies - one of the most important aspects of Clean Architecture. Infrastructure : where Repositories and Services are being defined. This layer pulls in the interfaces of repositories and services from the Application Layer and implements them in their own classes. Repositories are how we implement the database operations. They are classes that expose methods that perform a single database operation - like get_calibration , or create_calibration , or update_calibration . This means that we use the database library / driver in these classes only. They don't perform any data validation, just execute queries and mutations against the database and either throw our custom defined Errors or return results. Services are shared services that are being used across the application - like an authentication service, or email service, or implement external systems like Stripe (create payments, validate receipts etc...). These services also use and depend on other frameworks and libraries. That's why their implementation is kept here alongside the repositories. ~~Since we don't want any layer to depend on this one (and transitively depend on the database and all the services), we use the Dependency Inversion principle . This allows us to depend only on the interfaces defined in the Application Layer , instead of the implementations in the Infrastructure Layer . We use an Inversion of Control library like ioctopus to abstract the implementation behind the interfaces and \"inject\" it whenever we need it. We create the abstraction in the di directory. We \"bind\" the repositories, services, controllers, and use cases to Symbols, and we \"resolve\" them using those symbols when we need the actual implementation. That's how we can use the implementation, without needing to explicitly depend on it (import it).~~ # TODO: future implementation Folder hierarchy with descriptions src/ \u251c\u2500\u2500 config/ # singleton configuration \u2502 \u251c\u2500\u2500 database.py # returns SQLAlchemy SessionLocal instance or Engine \u2502 \u2514\u2500\u2500 environment.py # loads env variables, etc. \u251c\u2500\u2500 entities/ # \"Entities\" or \"core\" layer \u2502 \u251c\u2500\u2500 exceptions.py # Core \"custom\" exceptions, decorates base exception w/\"cause\" and \"messages\" \u2502 \u251c\u2500\u2500 models/ \u2502 \u2514\u2500\u2500 value_objects/ \u251c\u2500\u2500 application/ # \"Application\" layer \u2502 \u251c\u2500\u2500 repositories/ # (interfaces only) \u2502 \u251c\u2500\u2500 services/ # (interfaces only) \u2502 \u2514\u2500\u2500 use_cases/ # implementation of CA \"Use Cases\" \u2502 \u2514\u2500\u2500 exceptions.py # exceptions that are specific to a given \"Use Case\" \u251c\u2500\u2500 interface_adapters/ # \"Interface\" adapters layer from CA \u2502 \u251c\u2500\u2500 controllers/ # \"Controllers\" from CA \u2502 \u2514\u2500\u2500 presenters/ # \"Presenters\" from CA \u251c\u2500\u2500 drivers/ # \"Frameworks & Drivers\" layer \u2502 \u2514\u2500\u2500 rest/ # FastAPI framework \u2502 \u251c\u2500\u2500 routers/ # FastAPI request handlers \u2502 \u251c\u2500\u2500 schemas/ # FastAPI input and output schemas \u2502 \u251c\u2500\u2500 dependencies.py # FastAPI middleware \u2502 \u251c\u2500\u2500 exception_handlers.py # FastAPI exception wrappers \u2502 \u2514\u2500\u2500 main.py # FastAPI entrypoint \u2514\u2500\u2500 infrastructure/ # \"Infrastructure\" layer: implementation of interface from \"Application\" layer \u251c\u2500\u2500 repositories/ \u2502 \u251c\u2500\u2500 calibration_repository/ \u2502 \u2502 \u251c\u2500\u2500 mock_repository.py # implements in-memory \u2502 \u2502 \u251c\u2500\u2500 mongodb_repository.py # implements mongodb \u2502 \u2502 \u2514\u2500\u2500 postgres_repository.py # implements postgres \u2502 \u2514\u2500\u2500 orm_models.py # sqlalchemy-specific orm <-> system entity mapper \u2514\u2500\u2500 services/ Big Picture (w/o configs) \u251c\u2500\u2500 README.md \u251c\u2500\u2500 docs \u2502 \u251c\u2500\u2500 ARCHITECTURE.md \u2502 \u251c\u2500\u2500 CONTRIBUTING.md \u2502 \u251c\u2500\u2500 DATABASE.md \u2502 \u251c\u2500\u2500 DEVELOPER.md \u2502 \u251c\u2500\u2500 PROJECT.md \u2502 \u251c\u2500\u2500 TESTS.md \u2502 \u2514\u2500\u2500 WORKFLOWS.md \u251c\u2500\u2500 pyproject.toml \u251c\u2500\u2500 scripts \u2502 \u251c\u2500\u2500 bash_runner.py \u2502 \u251c\u2500\u2500 make_tree.py \u2502 \u251c\u2500\u2500 run_db.sh \u2502 \u251c\u2500\u2500 run_tests.sh \u2502 \u251c\u2500\u2500 run_tests_with_coverage.sh \u2502 \u251c\u2500\u2500 sample_data \u2502 \u2502 \u2514\u2500\u2500 sample_calibrations.json \u2502 \u2514\u2500\u2500 seed_database.py \u251c\u2500\u2500 src \u2502 \u251c\u2500\u2500 application \u2502 \u2502 \u251c\u2500\u2500 dtos \u2502 \u2502 \u2502 \u251c\u2500\u2500 get_calibrations_by_tag_dtos.py \u2502 \u2502 \u2502 \u2514\u2500\u2500 get_tags_for_calibration_dtos.py \u2502 \u2502 \u251c\u2500\u2500 repositories \u2502 \u2502 \u2502 \u251c\u2500\u2500 calibration_repository.py \u2502 \u2502 \u2502 \u2514\u2500\u2500 tag_repository.py \u2502 \u2502 \u251c\u2500\u2500 services \u2502 \u2502 \u2514\u2500\u2500 use_cases \u2502 \u2502 \u251c\u2500\u2500 calibrations \u2502 \u2502 \u2502 \u251c\u2500\u2500 add_calibration_tags.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 add_calibration_use_case.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 get_tags_for_calibration.py \u2502 \u2502 \u2502 \u2514\u2500\u2500 list_calibrations.py \u2502 \u2502 \u251c\u2500\u2500 exceptions.py \u2502 \u2502 \u2514\u2500\u2500 tags \u2502 \u2502 \u251c\u2500\u2500 add_bulk_tags_to_calibration.py \u2502 \u2502 \u251c\u2500\u2500 add_tag_to_calibration.py \u2502 \u2502 \u251c\u2500\u2500 create_tag.py \u2502 \u2502 \u251c\u2500\u2500 get_calibrations_by_tag.py \u2502 \u2502 \u251c\u2500\u2500 list_tags.py \u2502 \u2502 \u2514\u2500\u2500 remove_tag_from_calibration.py \u2502 \u251c\u2500\u2500 config \u2502 \u2502 \u251c\u2500\u2500 database.py \u2502 \u2502 \u2514\u2500\u2500 logger.py \u2502 \u251c\u2500\u2500 drivers \u2502 \u2502 \u2514\u2500\u2500 rest \u2502 \u2502 \u251c\u2500\u2500 dependencies.py \u2502 \u2502 \u251c\u2500\u2500 exception_handlers.py \u2502 \u2502 \u251c\u2500\u2500 main.py \u2502 \u2502 \u251c\u2500\u2500 routers \u2502 \u2502 \u2502 \u251c\u2500\u2500 calibration_router.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 health_router.py \u2502 \u2502 \u2502 \u2514\u2500\u2500 tag_router.py \u2502 \u2502 \u2514\u2500\u2500 schemas \u2502 \u2502 \u251c\u2500\u2500 calibration_schemas.py \u2502 \u2502 \u2514\u2500\u2500 tag_schemas.py \u2502 \u251c\u2500\u2500 entities \u2502 \u2502 \u251c\u2500\u2500 exceptions.py \u2502 \u2502 \u251c\u2500\u2500 models \u2502 \u2502 \u2502 \u251c\u2500\u2500 calibration.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 calibration_tag.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 calibration_tag_association.py \u2502 \u2502 \u2502 \u2514\u2500\u2500 tag.py \u2502 \u2502 \u2514\u2500\u2500 value_objects \u2502 \u2502 \u251c\u2500\u2500 calibration_type.py \u2502 \u2502 \u2514\u2500\u2500 iso_8601_timestamp.py \u2502 \u251c\u2500\u2500 infrastructure \u2502 \u2502 \u251c\u2500\u2500 orm_models \u2502 \u2502 \u2502 \u251c\u2500\u2500 base.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 calibration.py \u2502 \u2502 \u2502 \u2514\u2500\u2500 tag.py \u2502 \u2502 \u2514\u2500\u2500 repositories \u2502 \u2502 \u251c\u2500\u2500 calibration_repository \u2502 \u2502 \u2502 \u251c\u2500\u2500 in_memory_repository.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 mongodb_repository.py \u2502 \u2502 \u2502 \u2514\u2500\u2500 postgres_repository.py \u2502 \u2502 \u2514\u2500\u2500 tag_repository \u2502 \u2502 \u251c\u2500\u2500 mock_repository.py \u2502 \u2502 \u2514\u2500\u2500 postgres_repository.py \u2502 \u251c\u2500\u2500 interface_adapters \u2502 \u2502 \u251c\u2500\u2500 controllers \u2502 \u2502 \u2502 \u251c\u2500\u2500 calibrations \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 add_calibration_controller.py \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 get_tags_for_calibration_controller.py \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500 list_calibrations_controller.py \u2502 \u2502 \u2502 \u2514\u2500\u2500 tags \u2502 \u2502 \u2502 \u251c\u2500\u2500 add_bulk_tags_to_calibration_controller.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 add_tag_to_calibration_controller.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 create_tag_controller.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 get_calibrations_by_tag_controller.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 list_tags_controller.py \u2502 \u2502 \u2502 \u2514\u2500\u2500 remove_tag_from_calibration_controller.py \u2502 \u2502 \u2514\u2500\u2500 presenters \u2502 \u2502 \u251c\u2500\u2500 calibration_presenter.py \u2502 \u2502 \u2514\u2500\u2500 tag_presenter.py \u2502 \u2514\u2500\u2500 main.py \u2514\u2500\u2500 tests \u251c\u2500\u2500 e2e \u2502 \u251c\u2500\u2500 test_api_use_cases_e2e.py \u2502 \u2514\u2500\u2500 test_tag_archiving_e2e.py \u251c\u2500\u2500 integration \u2502 \u251c\u2500\u2500 drivers \u2502 \u2502 \u2514\u2500\u2500 rest \u2502 \u2502 \u251c\u2500\u2500 routers \u2502 \u2502 \u2502 \u2514\u2500\u2500 test_calibration_router.py \u2502 \u2502 \u251c\u2500\u2500 test_api_use_cases.py \u2502 \u2502 \u251c\u2500\u2500 test_calibration_add.py \u2502 \u2502 \u251c\u2500\u2500 test_calibration_add_tags.py \u2502 \u2502 \u251c\u2500\u2500 test_calibration_api.py \u2502 \u2502 \u2514\u2500\u2500 test_tagging_api.py \u2502 \u2514\u2500\u2500 repositories \u2502 \u2514\u2500\u2500 test_mongodb_calibration_repository.py \u251c\u2500\u2500 unit \u2502 \u251c\u2500\u2500 application \u2502 \u2502 \u2514\u2500\u2500 use_cases \u2502 \u2502 \u251c\u2500\u2500 calibrations \u2502 \u2502 \u2502 \u251c\u2500\u2500 add_calibration_tags_use_case_test.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 add_calibration_use_case_test.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 test_get_tags_for_calibration.py \u2502 \u2502 \u2502 \u2514\u2500\u2500 test_list_calibrations.py \u2502 \u2502 \u2514\u2500\u2500 tags \u2502 \u2502 \u251c\u2500\u2500 test_add_bulk_tags_to_calibration.py \u2502 \u2502 \u251c\u2500\u2500 test_add_tag_to_calibration.py \u2502 \u2502 \u251c\u2500\u2500 test_create_tag.py \u2502 \u2502 \u251c\u2500\u2500 test_get_calibrations_by_tag.py \u2502 \u2502 \u251c\u2500\u2500 test_list_tags.py \u2502 \u2502 \u2514\u2500\u2500 test_remove_tag_from_calibration.py \u2502 \u251c\u2500\u2500 infrastructure \u2502 \u2502 \u2514\u2500\u2500 repositories \u2502 \u2502 \u2514\u2500\u2500 test_calibration_repository.py \u2502 \u2514\u2500\u2500 interface_adapters \u2502 \u2514\u2500\u2500 controllers \u2502 \u251c\u2500\u2500 calibrations \u2502 \u2502 \u251c\u2500\u2500 test_add_calibration_controller.py \u2502 \u2502 \u251c\u2500\u2500 test_get_tags_for_calibration_controller.py \u2502 \u2502 \u2514\u2500\u2500 test_list_calibrations_controller.py \u2502 \u2514\u2500\u2500 tags \u2502 \u251c\u2500\u2500 test_add_bulk_tags_to_calibration_controller.py \u2502 \u251c\u2500\u2500 test_add_tag_to_calibration_controller.py \u2502 \u251c\u2500\u2500 test_create_tag_controller.py \u2502 \u251c\u2500\u2500 test_get_calibrations_by_tag_controller.py \u2502 \u251c\u2500\u2500 test_list_tags_controller.py \u2502 \u2514\u2500\u2500 test_remove_tag_from_calibration_controller.py \u2514\u2500\u2500 utils \u2514\u2500\u2500 entity_factories.py","title":"Architecture"},{"location":"ARCHITECTURE/#architecture","text":"","title":"Architecture"},{"location":"ARCHITECTURE/#grounding-inspiration","text":"This project uses Clean Architecture patterns. Hereafter \"CA\" will be used for \"Clean Architecture\". Background article by Bob Martin https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html Inspiration from existing CA implementations CA with Python - by R. Shaliamekh. clean-architecture-fastapi - by shaliamekh - associated repo for blog post CA in Next.js ](https://www.youtube.com/watch?v=jJVAla0dWJo) - video describing CA nextjs-clean-architecture - by nikolovlazar - associated repo for video Other similar architectures to Clean Architecture Hexagonal Architecture - (a.k.a. Ports and Adapters) by Alistair Cockburn Onion Architecture - by Jeffrey Palermo Screaming Architecture - by Uncle Bob (the same guy behind Clean Architecture)","title":"Grounding &amp; Inspiration"},{"location":"ARCHITECTURE/#diagrams","text":"The CA Diagram (sphere) - by Uncle Bob - by Uncle Bob The CA Diagram (simplified) - by nikolovlazar","title":"Diagrams"},{"location":"ARCHITECTURE/#original","text":"","title":"Original"},{"location":"ARCHITECTURE/#simplified","text":"","title":"\"Simplified\""},{"location":"ARCHITECTURE/#clean-architecture-in-brief","text":"Great summary of how to approach these layers in-practice with the project. Note: it's heavily borrowed from nikolovlazar... thank you! Clean Architecture is a set of rules that help us structure our applications in such way that they're easier to maintain and test, and their codebases are predictable. It's like a common language that developers understand, regardless of their technical backgrounds and programming language preferences. Clean Architecture, and similar/derived architectures, all have the same goal - separation of concerns . They introduce layers that bundle similar code together. The \"layering\" helps us achieve important aspects in our codebase: Independent of UI - the business logic is not coupled with the UI framework that's being used (in this case Next.js). The same system can be used in a CLI application, without having to change the business logic or rules. Independent of Database - the database implementation/operations are isolated in their own layer, so the rest of the app does not care about which database is being used, but communicates using Models . Independent of Frameworks - the business rules and logic simply don't know anything about the outside world. They receive data defined with plain objects/dictionaries, Services and Repositories to define their own logic and functionality. This allows us to use frameworks as tools, instead of having to \"mold\" our system into their implementations and limitations. If we use Route Handlers in our app's Drivers , and want to refactor some of them to use a different framework implementation all we need to do is just invoke the specific controllers in the new framework's manner, but the core business logic remains unchanged. Testable - the business logic and rules can easily be tested because it does not depend on the UI framework, or the database, or the web server, or any other external element that builds up our system. Clean Architecture achieves this through defining a dependency hierarchy - layers depend only on layers below them , but not above.","title":"Clean Architecture in Brief"},{"location":"ARCHITECTURE/#project-structure-only-the-important-parts","text":"app - Frameworks & Drivers Layer - basically everything Next.js (pages, server actions, components, styles etc...) or whatever \"consumes\" the app's logic ~~ di - Dependency Injection - a folder where we setup the DI container and the modules~~ # TODO: (future implementation) ~~ db - Everything DB - initializing the DB client, defining schema, migrations~~ # TODO: (future implementation) src - The \"root\" of the system application - Application Layer - holds use cases and interfaces for repositories and services entities - Entities Layer - holds models, value objects and custom errors/exceptions infrastructure - Infrastructure Layer - holds implementations of repositories and services, and pulls in the interfaces from application interface-adapters - Interface Adapters Layer - holds controllers that serve as an entry point to the system (used in Frameworks & Drivers layer to interact with the system) drivers - Frameworks & Drivers layer - holds implementation-specific details for a given framework (e.g. FastAPI routes) tests - Unit tests live here - the unit subfolder's structure matches src pyproject.toml - list of deps & configuration for python tools (linters, formatters, ) ~~Where the pylint-module-boundaries plugin is defined - this stops you from breaking the dependency rule ~~ # TODO: (future implementation) scripts - manual scripts to run project-wide actions (e.g. run tests) from bash terminal docs - project documentation .github/workflows - project cicd files","title":"Project structure (only the important parts)"},{"location":"ARCHITECTURE/#project-structure-developer-tooling","text":".pre-commit-config.yaml - rules triggered to run via got hooks cspell.config.yaml - custom dictionary to keep IDE's inspection pane \"clean\" .run - shared run configurations for JetBrains PyCharm IDE","title":"Project structure (Developer Tooling)"},{"location":"ARCHITECTURE/#layers-explanation","text":"Frameworks & Drivers : keeps all the UI framework functionality, and everything else that interacts with the system (eg AWS Lambdas, Stripe webhooks etc...). In this scenario, that's FastAPI Route Handlers This layer should only use Controllers , Models , and Errors , and must not import Use Cases , Repositories , and Services . Interface Adapters : defines Controllers and Presenters : Controllers perform authentication checks and input validation before passing the input to the specific use cases. Controllers orchestrate Use Cases. They don't implement any logic, but define the whole operations using the use cases. In short, they use \"Use Case\" input ports. Errors from deeper layers are bubbled up and being handled where controllers are being used. Controllers use Presenters to convert the data to a UI-friendly format just before returning it to the \"consumer\". This helps prevent leaking any sensitive properties, like emails or hashed passwords, and also helps us slim down the amount of data we're sending back to the client. In short, they implement Use Case output ports. Application : where the business logic lives. Sometimes called core . This layer defines the Use Cases and interfaces for the services and repositories. Use Cases : Represent individual operations, like \"Create Calibration\" or \"Sign In\" Accept pre-validated input (from controllers) and handle authorization checks . Use Repositories and Services to access data sources and communicate with external systems. Use cases should not use other use cases . That's a code smell. It means the use case does multiple things and should be broken down into multiple use cases. Interfaces for Repositories and Services: These are defined in this layer because we want to break out the dependency of their tools and frameworks (database drivers, email services etc...), so we'll implement them in the Infrastructure layer. Since the interfaces live in this layer, use cases (and transitively the upper layers) can access them through Dependency Injection . Dependency Injection allows us to split up the definitions (interfaces) from the implementations (classes) and keep them in a separate layer (infrastructure), but still allow their usage. Entities : where the Models and Exceptions are defined. Models : Define \"domain\" data shapes with plain JavaScript, without using \"database\" technologies. Models are not always tied to the database - sending emails require an external email service, not a database, but we still need to have a data shape that will help other layers communicate \"sending an email\". Models also define their own validation rules, which are called \"Enterprise Business Rules\". Rules that don't usually change, or are least likely to change when something external changes (page navigation, security, etc...). An example is a User model that defines a username field that must be at least 6 characters long and not include special characters . Exceptions : We want our own errors because we don't want to be bubbling up database-specific errors, or any type of errors that are specific to a library or framework. We catch errors that are coming from other libraries (for example SQAlchemy), and convert those errors to our own errors. That's how we can keep our core independent of any frameworks, libraries, and technologies - one of the most important aspects of Clean Architecture. Infrastructure : where Repositories and Services are being defined. This layer pulls in the interfaces of repositories and services from the Application Layer and implements them in their own classes. Repositories are how we implement the database operations. They are classes that expose methods that perform a single database operation - like get_calibration , or create_calibration , or update_calibration . This means that we use the database library / driver in these classes only. They don't perform any data validation, just execute queries and mutations against the database and either throw our custom defined Errors or return results. Services are shared services that are being used across the application - like an authentication service, or email service, or implement external systems like Stripe (create payments, validate receipts etc...). These services also use and depend on other frameworks and libraries. That's why their implementation is kept here alongside the repositories. ~~Since we don't want any layer to depend on this one (and transitively depend on the database and all the services), we use the Dependency Inversion principle . This allows us to depend only on the interfaces defined in the Application Layer , instead of the implementations in the Infrastructure Layer . We use an Inversion of Control library like ioctopus to abstract the implementation behind the interfaces and \"inject\" it whenever we need it. We create the abstraction in the di directory. We \"bind\" the repositories, services, controllers, and use cases to Symbols, and we \"resolve\" them using those symbols when we need the actual implementation. That's how we can use the implementation, without needing to explicitly depend on it (import it).~~ # TODO: future implementation","title":"Layers explanation"},{"location":"ARCHITECTURE/#folder-hierarchy-with-descriptions","text":"src/ \u251c\u2500\u2500 config/ # singleton configuration \u2502 \u251c\u2500\u2500 database.py # returns SQLAlchemy SessionLocal instance or Engine \u2502 \u2514\u2500\u2500 environment.py # loads env variables, etc. \u251c\u2500\u2500 entities/ # \"Entities\" or \"core\" layer \u2502 \u251c\u2500\u2500 exceptions.py # Core \"custom\" exceptions, decorates base exception w/\"cause\" and \"messages\" \u2502 \u251c\u2500\u2500 models/ \u2502 \u2514\u2500\u2500 value_objects/ \u251c\u2500\u2500 application/ # \"Application\" layer \u2502 \u251c\u2500\u2500 repositories/ # (interfaces only) \u2502 \u251c\u2500\u2500 services/ # (interfaces only) \u2502 \u2514\u2500\u2500 use_cases/ # implementation of CA \"Use Cases\" \u2502 \u2514\u2500\u2500 exceptions.py # exceptions that are specific to a given \"Use Case\" \u251c\u2500\u2500 interface_adapters/ # \"Interface\" adapters layer from CA \u2502 \u251c\u2500\u2500 controllers/ # \"Controllers\" from CA \u2502 \u2514\u2500\u2500 presenters/ # \"Presenters\" from CA \u251c\u2500\u2500 drivers/ # \"Frameworks & Drivers\" layer \u2502 \u2514\u2500\u2500 rest/ # FastAPI framework \u2502 \u251c\u2500\u2500 routers/ # FastAPI request handlers \u2502 \u251c\u2500\u2500 schemas/ # FastAPI input and output schemas \u2502 \u251c\u2500\u2500 dependencies.py # FastAPI middleware \u2502 \u251c\u2500\u2500 exception_handlers.py # FastAPI exception wrappers \u2502 \u2514\u2500\u2500 main.py # FastAPI entrypoint \u2514\u2500\u2500 infrastructure/ # \"Infrastructure\" layer: implementation of interface from \"Application\" layer \u251c\u2500\u2500 repositories/ \u2502 \u251c\u2500\u2500 calibration_repository/ \u2502 \u2502 \u251c\u2500\u2500 mock_repository.py # implements in-memory \u2502 \u2502 \u251c\u2500\u2500 mongodb_repository.py # implements mongodb \u2502 \u2502 \u2514\u2500\u2500 postgres_repository.py # implements postgres \u2502 \u2514\u2500\u2500 orm_models.py # sqlalchemy-specific orm <-> system entity mapper \u2514\u2500\u2500 services/","title":"Folder hierarchy with descriptions"},{"location":"ARCHITECTURE/#big-picture-wo-configs","text":"\u251c\u2500\u2500 README.md \u251c\u2500\u2500 docs \u2502 \u251c\u2500\u2500 ARCHITECTURE.md \u2502 \u251c\u2500\u2500 CONTRIBUTING.md \u2502 \u251c\u2500\u2500 DATABASE.md \u2502 \u251c\u2500\u2500 DEVELOPER.md \u2502 \u251c\u2500\u2500 PROJECT.md \u2502 \u251c\u2500\u2500 TESTS.md \u2502 \u2514\u2500\u2500 WORKFLOWS.md \u251c\u2500\u2500 pyproject.toml \u251c\u2500\u2500 scripts \u2502 \u251c\u2500\u2500 bash_runner.py \u2502 \u251c\u2500\u2500 make_tree.py \u2502 \u251c\u2500\u2500 run_db.sh \u2502 \u251c\u2500\u2500 run_tests.sh \u2502 \u251c\u2500\u2500 run_tests_with_coverage.sh \u2502 \u251c\u2500\u2500 sample_data \u2502 \u2502 \u2514\u2500\u2500 sample_calibrations.json \u2502 \u2514\u2500\u2500 seed_database.py \u251c\u2500\u2500 src \u2502 \u251c\u2500\u2500 application \u2502 \u2502 \u251c\u2500\u2500 dtos \u2502 \u2502 \u2502 \u251c\u2500\u2500 get_calibrations_by_tag_dtos.py \u2502 \u2502 \u2502 \u2514\u2500\u2500 get_tags_for_calibration_dtos.py \u2502 \u2502 \u251c\u2500\u2500 repositories \u2502 \u2502 \u2502 \u251c\u2500\u2500 calibration_repository.py \u2502 \u2502 \u2502 \u2514\u2500\u2500 tag_repository.py \u2502 \u2502 \u251c\u2500\u2500 services \u2502 \u2502 \u2514\u2500\u2500 use_cases \u2502 \u2502 \u251c\u2500\u2500 calibrations \u2502 \u2502 \u2502 \u251c\u2500\u2500 add_calibration_tags.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 add_calibration_use_case.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 get_tags_for_calibration.py \u2502 \u2502 \u2502 \u2514\u2500\u2500 list_calibrations.py \u2502 \u2502 \u251c\u2500\u2500 exceptions.py \u2502 \u2502 \u2514\u2500\u2500 tags \u2502 \u2502 \u251c\u2500\u2500 add_bulk_tags_to_calibration.py \u2502 \u2502 \u251c\u2500\u2500 add_tag_to_calibration.py \u2502 \u2502 \u251c\u2500\u2500 create_tag.py \u2502 \u2502 \u251c\u2500\u2500 get_calibrations_by_tag.py \u2502 \u2502 \u251c\u2500\u2500 list_tags.py \u2502 \u2502 \u2514\u2500\u2500 remove_tag_from_calibration.py \u2502 \u251c\u2500\u2500 config \u2502 \u2502 \u251c\u2500\u2500 database.py \u2502 \u2502 \u2514\u2500\u2500 logger.py \u2502 \u251c\u2500\u2500 drivers \u2502 \u2502 \u2514\u2500\u2500 rest \u2502 \u2502 \u251c\u2500\u2500 dependencies.py \u2502 \u2502 \u251c\u2500\u2500 exception_handlers.py \u2502 \u2502 \u251c\u2500\u2500 main.py \u2502 \u2502 \u251c\u2500\u2500 routers \u2502 \u2502 \u2502 \u251c\u2500\u2500 calibration_router.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 health_router.py \u2502 \u2502 \u2502 \u2514\u2500\u2500 tag_router.py \u2502 \u2502 \u2514\u2500\u2500 schemas \u2502 \u2502 \u251c\u2500\u2500 calibration_schemas.py \u2502 \u2502 \u2514\u2500\u2500 tag_schemas.py \u2502 \u251c\u2500\u2500 entities \u2502 \u2502 \u251c\u2500\u2500 exceptions.py \u2502 \u2502 \u251c\u2500\u2500 models \u2502 \u2502 \u2502 \u251c\u2500\u2500 calibration.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 calibration_tag.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 calibration_tag_association.py \u2502 \u2502 \u2502 \u2514\u2500\u2500 tag.py \u2502 \u2502 \u2514\u2500\u2500 value_objects \u2502 \u2502 \u251c\u2500\u2500 calibration_type.py \u2502 \u2502 \u2514\u2500\u2500 iso_8601_timestamp.py \u2502 \u251c\u2500\u2500 infrastructure \u2502 \u2502 \u251c\u2500\u2500 orm_models \u2502 \u2502 \u2502 \u251c\u2500\u2500 base.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 calibration.py \u2502 \u2502 \u2502 \u2514\u2500\u2500 tag.py \u2502 \u2502 \u2514\u2500\u2500 repositories \u2502 \u2502 \u251c\u2500\u2500 calibration_repository \u2502 \u2502 \u2502 \u251c\u2500\u2500 in_memory_repository.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 mongodb_repository.py \u2502 \u2502 \u2502 \u2514\u2500\u2500 postgres_repository.py \u2502 \u2502 \u2514\u2500\u2500 tag_repository \u2502 \u2502 \u251c\u2500\u2500 mock_repository.py \u2502 \u2502 \u2514\u2500\u2500 postgres_repository.py \u2502 \u251c\u2500\u2500 interface_adapters \u2502 \u2502 \u251c\u2500\u2500 controllers \u2502 \u2502 \u2502 \u251c\u2500\u2500 calibrations \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 add_calibration_controller.py \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 get_tags_for_calibration_controller.py \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500 list_calibrations_controller.py \u2502 \u2502 \u2502 \u2514\u2500\u2500 tags \u2502 \u2502 \u2502 \u251c\u2500\u2500 add_bulk_tags_to_calibration_controller.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 add_tag_to_calibration_controller.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 create_tag_controller.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 get_calibrations_by_tag_controller.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 list_tags_controller.py \u2502 \u2502 \u2502 \u2514\u2500\u2500 remove_tag_from_calibration_controller.py \u2502 \u2502 \u2514\u2500\u2500 presenters \u2502 \u2502 \u251c\u2500\u2500 calibration_presenter.py \u2502 \u2502 \u2514\u2500\u2500 tag_presenter.py \u2502 \u2514\u2500\u2500 main.py \u2514\u2500\u2500 tests \u251c\u2500\u2500 e2e \u2502 \u251c\u2500\u2500 test_api_use_cases_e2e.py \u2502 \u2514\u2500\u2500 test_tag_archiving_e2e.py \u251c\u2500\u2500 integration \u2502 \u251c\u2500\u2500 drivers \u2502 \u2502 \u2514\u2500\u2500 rest \u2502 \u2502 \u251c\u2500\u2500 routers \u2502 \u2502 \u2502 \u2514\u2500\u2500 test_calibration_router.py \u2502 \u2502 \u251c\u2500\u2500 test_api_use_cases.py \u2502 \u2502 \u251c\u2500\u2500 test_calibration_add.py \u2502 \u2502 \u251c\u2500\u2500 test_calibration_add_tags.py \u2502 \u2502 \u251c\u2500\u2500 test_calibration_api.py \u2502 \u2502 \u2514\u2500\u2500 test_tagging_api.py \u2502 \u2514\u2500\u2500 repositories \u2502 \u2514\u2500\u2500 test_mongodb_calibration_repository.py \u251c\u2500\u2500 unit \u2502 \u251c\u2500\u2500 application \u2502 \u2502 \u2514\u2500\u2500 use_cases \u2502 \u2502 \u251c\u2500\u2500 calibrations \u2502 \u2502 \u2502 \u251c\u2500\u2500 add_calibration_tags_use_case_test.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 add_calibration_use_case_test.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 test_get_tags_for_calibration.py \u2502 \u2502 \u2502 \u2514\u2500\u2500 test_list_calibrations.py \u2502 \u2502 \u2514\u2500\u2500 tags \u2502 \u2502 \u251c\u2500\u2500 test_add_bulk_tags_to_calibration.py \u2502 \u2502 \u251c\u2500\u2500 test_add_tag_to_calibration.py \u2502 \u2502 \u251c\u2500\u2500 test_create_tag.py \u2502 \u2502 \u251c\u2500\u2500 test_get_calibrations_by_tag.py \u2502 \u2502 \u251c\u2500\u2500 test_list_tags.py \u2502 \u2502 \u2514\u2500\u2500 test_remove_tag_from_calibration.py \u2502 \u251c\u2500\u2500 infrastructure \u2502 \u2502 \u2514\u2500\u2500 repositories \u2502 \u2502 \u2514\u2500\u2500 test_calibration_repository.py \u2502 \u2514\u2500\u2500 interface_adapters \u2502 \u2514\u2500\u2500 controllers \u2502 \u251c\u2500\u2500 calibrations \u2502 \u2502 \u251c\u2500\u2500 test_add_calibration_controller.py \u2502 \u2502 \u251c\u2500\u2500 test_get_tags_for_calibration_controller.py \u2502 \u2502 \u2514\u2500\u2500 test_list_calibrations_controller.py \u2502 \u2514\u2500\u2500 tags \u2502 \u251c\u2500\u2500 test_add_bulk_tags_to_calibration_controller.py \u2502 \u251c\u2500\u2500 test_add_tag_to_calibration_controller.py \u2502 \u251c\u2500\u2500 test_create_tag_controller.py \u2502 \u251c\u2500\u2500 test_get_calibrations_by_tag_controller.py \u2502 \u251c\u2500\u2500 test_list_tags_controller.py \u2502 \u2514\u2500\u2500 test_remove_tag_from_calibration_controller.py \u2514\u2500\u2500 utils \u2514\u2500\u2500 entity_factories.py","title":"Big Picture (w/o configs)"},{"location":"CONTRIBUTING/","text":"Pre-commit Hooks The project uses pre-commit hooks to ensure code quality. These are configured in .pre-commit-config.yaml . Installed Hooks Hook Description When it Runs conventional-pre-commit Enforces Conventional Commits format On commit message run_tests Runs project tests Before commit trailing-whitespace Removes trailing whitespace Before commit end-of-file-fixer Ensures files end with newline Before commit check-toml Validates TOML files Before commit check-yaml Validates YAML files Before commit check-added-large-files Prevents large file commits Before commit ruff Lints Python code Before commit ruff-format Formats Python code Before commit pyright Type checks Python code Before commit uv-lock Updates dependency lock file Before commit Using Pre-commit # Install the hooks pre-commit install --install-hooks # Run all hooks manually. Note: errors in alembic directory should be ignored. pre-commit run --all-files # Run specific hook pre-commit run ruff --all-files Commit Message Format We use conventional commits with the following types: feat : New feature fix : Bug fix refactor : Code change that neither fixes a bug nor adds a feature test : Adding missing tests or correcting existing tests style : Changes that do not affect the meaning of the code chore : Other changes that don't modify src or test files build : Changes that affect the build system or external dependencies ci : Changes to CI configuration files and scripts docs : Documentation only changes wip : Work in progress Example: git commit -m \"feat: add user authentication\"","title":"CONTRIBUTING"},{"location":"CONTRIBUTING/#pre-commit-hooks","text":"The project uses pre-commit hooks to ensure code quality. These are configured in .pre-commit-config.yaml .","title":"Pre-commit Hooks"},{"location":"CONTRIBUTING/#installed-hooks","text":"Hook Description When it Runs conventional-pre-commit Enforces Conventional Commits format On commit message run_tests Runs project tests Before commit trailing-whitespace Removes trailing whitespace Before commit end-of-file-fixer Ensures files end with newline Before commit check-toml Validates TOML files Before commit check-yaml Validates YAML files Before commit check-added-large-files Prevents large file commits Before commit ruff Lints Python code Before commit ruff-format Formats Python code Before commit pyright Type checks Python code Before commit uv-lock Updates dependency lock file Before commit","title":"Installed Hooks"},{"location":"CONTRIBUTING/#using-pre-commit","text":"# Install the hooks pre-commit install --install-hooks # Run all hooks manually. Note: errors in alembic directory should be ignored. pre-commit run --all-files # Run specific hook pre-commit run ruff --all-files","title":"Using Pre-commit"},{"location":"CONTRIBUTING/#commit-message-format","text":"We use conventional commits with the following types: feat : New feature fix : Bug fix refactor : Code change that neither fixes a bug nor adds a feature test : Adding missing tests or correcting existing tests style : Changes that do not affect the meaning of the code chore : Other changes that don't modify src or test files build : Changes that affect the build system or external dependencies ci : Changes to CI configuration files and scripts docs : Documentation only changes wip : Work in progress Example: git commit -m \"feat: add user authentication\"","title":"Commit Message Format"},{"location":"DATABASE/","text":"Database Management This document covers database management, migrations, and best practices for this project. Overview The project uses: PostgreSQL as the database SQLAlchemy for ORM and database operations Alembic for database migrations Automatic migration generation from SQLAlchemy models Directory Structure src/ \u251c\u2500\u2500 infrastructure/ \u2502 \u2514\u2500\u2500 orm_models/ # SQLAlchemy models \u251c\u2500\u2500 config/ \u2502 \u2514\u2500\u2500 database.py # Database configuration \u2514\u2500\u2500 alembic/ \u251c\u2500\u2500 versions/ # Migration version files \u251c\u2500\u2500 env.py # Migration environment configuration \u2514\u2500\u2500 script.py.mako # Migration script template Common Operations The project provides several commands for database management: Database Management The service uses PostgreSQL for data storage and Alembic for database migrations. Key commands: # Initialize database and run migrations uv run db_init # Apply pending migrations uv run db_migrate # Create a new migration uv run db_create \"Description of changes\" # Seed data uv run db_seed Migration Management Creating Migrations When you modify SQLAlchemy models in orm_models/ , create a new migration: uv run db_create \"Add status column to Calibration model\" Always: Review the generated migration in alembic/versions/ Check indexes and constraints Add any necessary data migrations Run tests before committing Applying Migrations To apply pending migrations: # Development environment uv run db_migrate # Test environment PYTHON_ENV=test uv run db_migrate Advanced Operations For advanced cases, you can use direct Alembic commands: # Roll back one migration PYTHONPATH=./src uv run alembic downgrade -1 # View migration history PYTHONPATH=./src uv run alembic history --verbose # Roll back to specific version PYTHONPATH=./src uv run alembic downgrade <version_id> Best Practices 1. Migration Management One migration per model change Write descriptive migration messages Include model name in migration message Review generated migrations before committing Test both upgrade and downgrade paths 2. Data Safety Always backup production data before migrations Test migrations on development first Include data migrations when needed Verify data integrity after migration 3. Development Workflow Create migrations in feature branches Run full test suite after migrations Document significant migrations Use appropriate environment for testing 4. Error Handling Never edit committed migrations Create new migrations for fixes Roll back failed migrations cleanly Check database state before retrying Environment Configuration The database system uses the project's layered environment configuration: .env - Base defaults (in git) .env.local - Local overrides (git-ignored) .env.{ENV} - Environment specific (in git) .env.{ENV}.local - Environment specific local overrides (git-ignored) Example configurations: # .env (base defaults) DATABASE_URL=postgresql+asyncpg://dev-user:password@localhost:5777/dev_db # .env.test DATABASE_URL=postgresql+asyncpg://test-user:password@localhost:5778/test_db Troubleshooting 1. Migration Not Detected Ensure model is imported in orm_models/__init__.py Verify model inherits from Base Check for circular imports Run with --verbose flag for more details 2. Connection Issues # Verify database is running docker compose ps # Check connection uv run db_init # Reset database (development only) docker compose down -v --rmi local uv run db_init 3. Migration Conflicts Never edit committed migrations Create new migrations for fixes Use alembic history to check state Consider rolling back if needed 4. Environment Issues # Check current settings cat .env cat .env.local # If it exists # Verify environment echo $PYTHON_ENV echo $DATABASE_URL For more information about development workflows, see DEVELOPER.md .","title":"Database Management"},{"location":"DATABASE/#database-management","text":"This document covers database management, migrations, and best practices for this project.","title":"Database Management"},{"location":"DATABASE/#overview","text":"The project uses: PostgreSQL as the database SQLAlchemy for ORM and database operations Alembic for database migrations Automatic migration generation from SQLAlchemy models","title":"Overview"},{"location":"DATABASE/#directory-structure","text":"src/ \u251c\u2500\u2500 infrastructure/ \u2502 \u2514\u2500\u2500 orm_models/ # SQLAlchemy models \u251c\u2500\u2500 config/ \u2502 \u2514\u2500\u2500 database.py # Database configuration \u2514\u2500\u2500 alembic/ \u251c\u2500\u2500 versions/ # Migration version files \u251c\u2500\u2500 env.py # Migration environment configuration \u2514\u2500\u2500 script.py.mako # Migration script template","title":"Directory Structure"},{"location":"DATABASE/#common-operations","text":"The project provides several commands for database management:","title":"Common Operations"},{"location":"DATABASE/#database-management_1","text":"The service uses PostgreSQL for data storage and Alembic for database migrations. Key commands: # Initialize database and run migrations uv run db_init # Apply pending migrations uv run db_migrate # Create a new migration uv run db_create \"Description of changes\" # Seed data uv run db_seed","title":"Database Management"},{"location":"DATABASE/#migration-management","text":"","title":"Migration Management"},{"location":"DATABASE/#creating-migrations","text":"When you modify SQLAlchemy models in orm_models/ , create a new migration: uv run db_create \"Add status column to Calibration model\" Always: Review the generated migration in alembic/versions/ Check indexes and constraints Add any necessary data migrations Run tests before committing","title":"Creating Migrations"},{"location":"DATABASE/#applying-migrations","text":"To apply pending migrations: # Development environment uv run db_migrate # Test environment PYTHON_ENV=test uv run db_migrate","title":"Applying Migrations"},{"location":"DATABASE/#advanced-operations","text":"For advanced cases, you can use direct Alembic commands: # Roll back one migration PYTHONPATH=./src uv run alembic downgrade -1 # View migration history PYTHONPATH=./src uv run alembic history --verbose # Roll back to specific version PYTHONPATH=./src uv run alembic downgrade <version_id>","title":"Advanced Operations"},{"location":"DATABASE/#best-practices","text":"","title":"Best Practices"},{"location":"DATABASE/#1-migration-management","text":"One migration per model change Write descriptive migration messages Include model name in migration message Review generated migrations before committing Test both upgrade and downgrade paths","title":"1. Migration Management"},{"location":"DATABASE/#2-data-safety","text":"Always backup production data before migrations Test migrations on development first Include data migrations when needed Verify data integrity after migration","title":"2. Data Safety"},{"location":"DATABASE/#3-development-workflow","text":"Create migrations in feature branches Run full test suite after migrations Document significant migrations Use appropriate environment for testing","title":"3. Development Workflow"},{"location":"DATABASE/#4-error-handling","text":"Never edit committed migrations Create new migrations for fixes Roll back failed migrations cleanly Check database state before retrying","title":"4. Error Handling"},{"location":"DATABASE/#environment-configuration","text":"The database system uses the project's layered environment configuration: .env - Base defaults (in git) .env.local - Local overrides (git-ignored) .env.{ENV} - Environment specific (in git) .env.{ENV}.local - Environment specific local overrides (git-ignored) Example configurations: # .env (base defaults) DATABASE_URL=postgresql+asyncpg://dev-user:password@localhost:5777/dev_db # .env.test DATABASE_URL=postgresql+asyncpg://test-user:password@localhost:5778/test_db","title":"Environment Configuration"},{"location":"DATABASE/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"DATABASE/#1-migration-not-detected","text":"Ensure model is imported in orm_models/__init__.py Verify model inherits from Base Check for circular imports Run with --verbose flag for more details","title":"1. Migration Not Detected"},{"location":"DATABASE/#2-connection-issues","text":"# Verify database is running docker compose ps # Check connection uv run db_init # Reset database (development only) docker compose down -v --rmi local uv run db_init","title":"2. Connection Issues"},{"location":"DATABASE/#3-migration-conflicts","text":"Never edit committed migrations Create new migrations for fixes Use alembic history to check state Consider rolling back if needed","title":"3. Migration Conflicts"},{"location":"DATABASE/#4-environment-issues","text":"# Check current settings cat .env cat .env.local # If it exists # Verify environment echo $PYTHON_ENV echo $DATABASE_URL For more information about development workflows, see DEVELOPER.md .","title":"4. Environment Issues"},{"location":"DEVELOPER/","text":"Developer Guide This guide covers day-to-day development workflows and commands. For initial setup instructions, see the README.md . Environment Configuration The project uses layered environment files for configuration: .env - Base defaults (in git) .env.local - Local overrides (git-ignored) .env.{ENV} - Environment specific (in git) Environment files are loaded in the order above, with later files overriding earlier ones. The {ENV} placeholder is replaced with the value of PYTHON_ENV (defaults to \"development\"). Example: To run in test environment: PYTHON_ENV=test uv run db_init # Will use .env \u2192 .env.local \u2192 .env.test \u2192 .env.test.local Available Project Commands All commands are run using uv run <command> . Here's a complete list: Command Description Common Use dev Start the development server Local development check Runs all \"before committing\" cmds Local development format Run code formatters Before committing lint Run linters Before committing test Run unit and integration tests Before committing test_debug Run test and prints log_test_step output Debugging failed tests test_cov Run tests with coverage report CI/CD, coverage checks typecheck Run type checker Before committing db_init Initialize database and run migrations First-time setup, reset DB db_migrate Apply pending migrations After pulling new migrations db_create Create a new migration After model changes setup Full setup (init DB and run tests) First-time setup, CI/CD cp_iso Copy ISO timestamp to clipboard Creating timestamps cp_ulid Copy ULID to clipboard Creating unique IDs cp_uuid Copy UUID to clipboard Creating unique IDs __see: pyproject.toml 's [project.scripts] for details. All are proxied through the scripts/bash_runner.py module. Common Development Workflows 1. Daily Development Start your day with: # Pull latest changes git pull # Apply any new migrations uv run db_migrate # Start the development server uv run dev 2. Making Changes When modifying code periodically run: # Format and lint code, check types, run tests uv run check 3. Database Changes see DATABASE.md 4. Pre-commit Checklist The pre-commit hooks will run automatically, but you can also run them manually: # Run all pre-commit hooks uv run pre-commit run --all-files # If all pass, commit your changes git add . git commit -m \"feat: your feature description\" 5. Running Tests see TESTS.md Best Practices Environment Variables Never commit sensitive values to git Use .env.local for local development overrides Use environment-specific files for different configurations Database Migrations One migration per model change Write meaningful migration messages Always run tests after applying migrations Code Quality Let pre-commit hooks run automatically Fix issues before committing Keep test coverage high Testing Write tests before fixing bugs Update tests when changing features Use appropriate test environment Running on localhost without Docker Compose Install python runtime and package manager uv brew install uv Verify executable is found in $PATH bash which uv Troubleshooting: open a new terminal if a directory is not sent to stdout Start db container, initialize database, and run migrations bash uv run setup (optional) Seed db: bash uv run db_seed Troubleshooting: run alembic directly using uv bash PYTHONPATH=${PYTHONPATH:-./src} uv run alembic upgrade head Start the development server: bash uv run fastapi dev src/drivers/rest/main.py Troubleshooting Common issues and solutions: Database Connection Issues bash # Reset database and migrations uv run db_init Environment Issues bash # Verify environment cat .env cat .env.local # If it exists Pre-commit Hook Issues bash # Update hooks to latest version pre-commit clean pre-commit install --install-hooks Test Database Issues bash # Run with test environment PYTHON_ENV=test uv run db_init PYTHON_ENV=test uv run test For more detailed information about the architecture and design decisions, see ARCHITECTURE.md .","title":"Developers"},{"location":"DEVELOPER/#developer-guide","text":"This guide covers day-to-day development workflows and commands. For initial setup instructions, see the README.md .","title":"Developer Guide"},{"location":"DEVELOPER/#environment-configuration","text":"The project uses layered environment files for configuration: .env - Base defaults (in git) .env.local - Local overrides (git-ignored) .env.{ENV} - Environment specific (in git) Environment files are loaded in the order above, with later files overriding earlier ones. The {ENV} placeholder is replaced with the value of PYTHON_ENV (defaults to \"development\"). Example: To run in test environment: PYTHON_ENV=test uv run db_init # Will use .env \u2192 .env.local \u2192 .env.test \u2192 .env.test.local","title":"Environment Configuration"},{"location":"DEVELOPER/#available-project-commands","text":"All commands are run using uv run <command> . Here's a complete list: Command Description Common Use dev Start the development server Local development check Runs all \"before committing\" cmds Local development format Run code formatters Before committing lint Run linters Before committing test Run unit and integration tests Before committing test_debug Run test and prints log_test_step output Debugging failed tests test_cov Run tests with coverage report CI/CD, coverage checks typecheck Run type checker Before committing db_init Initialize database and run migrations First-time setup, reset DB db_migrate Apply pending migrations After pulling new migrations db_create Create a new migration After model changes setup Full setup (init DB and run tests) First-time setup, CI/CD cp_iso Copy ISO timestamp to clipboard Creating timestamps cp_ulid Copy ULID to clipboard Creating unique IDs cp_uuid Copy UUID to clipboard Creating unique IDs __see: pyproject.toml 's [project.scripts] for details. All are proxied through the scripts/bash_runner.py module.","title":"Available Project Commands"},{"location":"DEVELOPER/#common-development-workflows","text":"","title":"Common Development Workflows"},{"location":"DEVELOPER/#1-daily-development","text":"Start your day with: # Pull latest changes git pull # Apply any new migrations uv run db_migrate # Start the development server uv run dev","title":"1. Daily Development"},{"location":"DEVELOPER/#2-making-changes","text":"When modifying code periodically run: # Format and lint code, check types, run tests uv run check","title":"2. Making Changes"},{"location":"DEVELOPER/#3-database-changes","text":"see DATABASE.md","title":"3. Database Changes"},{"location":"DEVELOPER/#4-pre-commit-checklist","text":"The pre-commit hooks will run automatically, but you can also run them manually: # Run all pre-commit hooks uv run pre-commit run --all-files # If all pass, commit your changes git add . git commit -m \"feat: your feature description\"","title":"4. Pre-commit Checklist"},{"location":"DEVELOPER/#5-running-tests","text":"see TESTS.md","title":"5. Running Tests"},{"location":"DEVELOPER/#best-practices","text":"Environment Variables Never commit sensitive values to git Use .env.local for local development overrides Use environment-specific files for different configurations Database Migrations One migration per model change Write meaningful migration messages Always run tests after applying migrations Code Quality Let pre-commit hooks run automatically Fix issues before committing Keep test coverage high Testing Write tests before fixing bugs Update tests when changing features Use appropriate test environment","title":"Best Practices"},{"location":"DEVELOPER/#running-on-localhost-without-docker-compose","text":"Install python runtime and package manager uv brew install uv Verify executable is found in $PATH bash which uv Troubleshooting: open a new terminal if a directory is not sent to stdout Start db container, initialize database, and run migrations bash uv run setup (optional) Seed db: bash uv run db_seed Troubleshooting: run alembic directly using uv bash PYTHONPATH=${PYTHONPATH:-./src} uv run alembic upgrade head Start the development server: bash uv run fastapi dev src/drivers/rest/main.py","title":"Running on localhost without Docker Compose"},{"location":"DEVELOPER/#troubleshooting","text":"Common issues and solutions: Database Connection Issues bash # Reset database and migrations uv run db_init Environment Issues bash # Verify environment cat .env cat .env.local # If it exists Pre-commit Hook Issues bash # Update hooks to latest version pre-commit clean pre-commit install --install-hooks Test Database Issues bash # Run with test environment PYTHON_ENV=test uv run db_init PYTHON_ENV=test uv run test For more detailed information about the architecture and design decisions, see ARCHITECTURE.md .","title":"Troubleshooting"},{"location":"PROJECT/","text":"Senior Backend Engineer - ISW | Take Home Overview This backend service is designed to manage calibrations of a hardware device. Each calibration includes: calibration_type value timestamp username Calibrations can be tagged with arbitrary strings to describe different states of a device. Tags can be added or removed from calibrations, and the tagging history is preserved. Technology Stack Language: Python Database: PostgreSQL or SQLite Libraries: See: pyproject.toml Use Cases & API Endpoints 1. Create a New Calibration Use Case: AddCalibrationUseCase application.use_cases.calibrations.add_calibration.py Endpoint: POST /calibrations Input: : { \"calibration_type\": \"string\", \"value\": \"float\", \"timestamp\": \"string (ISO 8601)\", \"username\": \"string\" } Output: { \"calibration_id\": \"uuid\" } 2. Query Calibrations by Filter list_calibrations_use_case Use Case: ListCalibrationsUseCase application.use_cases.calibrations.list_calibrations.py Endpoint: GET /calibrations Query Parameters: username : string timestamp : string (ISO 8601) calibration_type : string Output: [ { \"calibration_id\": \"uuid\", \"calibration_type\": \"string\", \"value\": \"float\", \"timestamp\": \"string (ISO 8601)\", \"username\": \"string\" } ] 3. Tagging Support 3a. Add a tag to a Calibration Use Case: AddTagToCalibrationUseCase application.use_cases.tags.add_tag_to_calibration.py Endpoint: POST /calibrations/{calibration_id}/tags Input: { \"tag\": \"string\" } Output: body json { \"message\": \"Tag added successfully\" } 3b. Removing a tag Use Case: RemoveTagFromCalibrationUseCase application.use_cases.tags.remove_tag_from_calibration.py Endpoint: DELETE /calibrations/{calibration_id}/tags/{tag_name} application.use_cases.tags.remove_tag_from_calibration Input: path: tag Output: body: json { \"message\": \"Tag removed successfully\" } Notes: Each calibration can be tagged and untagged with any number of tags Each tag is an arbitrary string i.e. the tags are not pre-defined (examples: \"current-state\" , \"baseline-2025\" ) Whenever a calibration is tagged or untagged those times are recorded 4. Retrieve Calibrations by Tag Use Case : GetCalibrationsByTagUseCase - application.use_cases.tags.get_calibrations_by_tag.py Endpoint: GET /tags/{tag}/calibrations Query Parameters: timestamp : string (ISO 8601) username : string Output: body TODO: (docs): add Response Schema Notes: Output: The list of calibrations associated with that tag at that time (i.e., calibrations added to the tag at or before that time, and not removed before that time) 5. Query Tags Associated with a Calibration Use Case : GetTagsForCalibrationUseCase - application.use_cases.calibrations.get_tags_for_calibration.py Endpoint: GET /calibrations/{calibration_id}/tags Query Parameters: timestamp : string (ISO 8601) Output: [ \"tag1\", \"tag2\", \"tag3\" ] Notes: Given a calibration primary key and a timestamp, retrieve all the tags that it was a part of at that time Sample Calibration Data See scripts/sample_data for the full object. [ { \"calibration_type\": \"offset\", \"value\": 1.0, \"username\": \"alice\" } ]","title":"Project"},{"location":"PROJECT/#senior-backend-engineer-isw-take-home","text":"","title":"Senior Backend Engineer - ISW | Take Home"},{"location":"PROJECT/#overview","text":"This backend service is designed to manage calibrations of a hardware device. Each calibration includes: calibration_type value timestamp username Calibrations can be tagged with arbitrary strings to describe different states of a device. Tags can be added or removed from calibrations, and the tagging history is preserved.","title":"Overview"},{"location":"PROJECT/#technology-stack","text":"Language: Python Database: PostgreSQL or SQLite Libraries: See: pyproject.toml","title":"Technology Stack"},{"location":"PROJECT/#use-cases-api-endpoints","text":"","title":"Use Cases &amp; API Endpoints"},{"location":"PROJECT/#1-create-a-new-calibration","text":"Use Case: AddCalibrationUseCase application.use_cases.calibrations.add_calibration.py Endpoint: POST /calibrations Input: : { \"calibration_type\": \"string\", \"value\": \"float\", \"timestamp\": \"string (ISO 8601)\", \"username\": \"string\" } Output: { \"calibration_id\": \"uuid\" }","title":"1. Create a New Calibration"},{"location":"PROJECT/#2-query-calibrations-by-filter-list_calibrations_use_case","text":"Use Case: ListCalibrationsUseCase application.use_cases.calibrations.list_calibrations.py Endpoint: GET /calibrations Query Parameters: username : string timestamp : string (ISO 8601) calibration_type : string Output: [ { \"calibration_id\": \"uuid\", \"calibration_type\": \"string\", \"value\": \"float\", \"timestamp\": \"string (ISO 8601)\", \"username\": \"string\" } ]","title":"2. Query Calibrations by Filter list_calibrations_use_case"},{"location":"PROJECT/#3-tagging-support","text":"","title":"3. Tagging Support"},{"location":"PROJECT/#3a-add-a-tag-to-a-calibration","text":"Use Case: AddTagToCalibrationUseCase application.use_cases.tags.add_tag_to_calibration.py Endpoint: POST /calibrations/{calibration_id}/tags Input: { \"tag\": \"string\" } Output: body json { \"message\": \"Tag added successfully\" }","title":"3a. Add a tag to a Calibration"},{"location":"PROJECT/#3b-removing-a-tag","text":"Use Case: RemoveTagFromCalibrationUseCase application.use_cases.tags.remove_tag_from_calibration.py Endpoint: DELETE /calibrations/{calibration_id}/tags/{tag_name} application.use_cases.tags.remove_tag_from_calibration Input: path: tag Output: body: json { \"message\": \"Tag removed successfully\" } Notes: Each calibration can be tagged and untagged with any number of tags Each tag is an arbitrary string i.e. the tags are not pre-defined (examples: \"current-state\" , \"baseline-2025\" ) Whenever a calibration is tagged or untagged those times are recorded","title":"3b. Removing a tag"},{"location":"PROJECT/#4-retrieve-calibrations-by-tag","text":"Use Case : GetCalibrationsByTagUseCase - application.use_cases.tags.get_calibrations_by_tag.py Endpoint: GET /tags/{tag}/calibrations Query Parameters: timestamp : string (ISO 8601) username : string Output: body","title":"4. Retrieve Calibrations by Tag"},{"location":"PROJECT/#todo-docs-add-response-schema","text":"Notes: Output: The list of calibrations associated with that tag at that time (i.e., calibrations added to the tag at or before that time, and not removed before that time)","title":"TODO: (docs): add Response Schema"},{"location":"PROJECT/#5-query-tags-associated-with-a-calibration","text":"Use Case : GetTagsForCalibrationUseCase - application.use_cases.calibrations.get_tags_for_calibration.py Endpoint: GET /calibrations/{calibration_id}/tags Query Parameters: timestamp : string (ISO 8601) Output: [ \"tag1\", \"tag2\", \"tag3\" ] Notes: Given a calibration primary key and a timestamp, retrieve all the tags that it was a part of at that time","title":"5. Query Tags Associated with a Calibration"},{"location":"PROJECT/#sample-calibration-data","text":"See scripts/sample_data for the full object. [ { \"calibration_type\": \"offset\", \"value\": 1.0, \"username\": \"alice\" } ]","title":"Sample Calibration Data"},{"location":"TESTS/","text":"Testing Strategy for Calibration Service This document outlines the testing strategy for the Calibration Service, following Clean Architecture principles. Test Structure The test suite is organized into the following categories: Note: ideally tests/unit should mirror the src folder Unit Tests : Testing individual components in isolation tests/unit/entities : Tests for entity models and validation tests/unit/application : Tests for use cases and business logic tests/unit/infrastructure : Tests for repositories and services tests/unit/interface_adapters : Tests for controllers tests/unit/use_cases : Tests for use cases Integration Tests : Testing the interaction between components tests/integration : API endpoint testing with in-memory repositories End-to-End Tests : Testing the entire system (future implementation) tests/e2e : Full system tests with external dependencies (e.g. live db) Test Dependencies The test suite uses the following dependencies: pytest : The core testing framework httpx : HTTP client for testing FastAPI endpoints pytest-asyncio : Support for asynchronous tests pytest-cov : Code coverage reporting Running Tests See: README for core tests for this project. Different test scenarios: # Run all tests uv run test # Run with coverage uv run test_cov # Run in test environment PYTHON_ENV=test uv run test Tests can also be run using the run_tests.sh script: bash ./scripts/run_tests.sh [!NOTE] run_tests is executed by pre-commit as a pre-commit hook. More info in Generate coverage reports using the run_tests_with_coverage.sh script: bash ./scripts/run_tests_with_coverage.sh Or, run manually: ```bash # Run all tests PYTHONPATH=./src python -m pytest -v --no-cov # Run unit tests only python -m pytest tests/unit -v --no-cov # Run integration tests only python -m pytest tests/integration -v --no-cov # Run with coverage (pytest.ini passes coverage flags by default) python -m pytest ``` Test Data Unit Tests : Use mock objects and in-memory repositories Integration Tests : Use in-memory repositories for isolation ~~- E2E Tests : Will use test databases or containerized services~~ (future) Clean Architecture Testing Approach Our (ideal) testing follows Clean Architecture principles: Entities Tests : Verify that our core models work correctly Use Case Tests : Ensure business rules are correctly implemented Interface Adapter Tests : Validate controllers and presenters Framework Tests : Test the FastAPI endpoints By following this approach, we can ensure that our business logic remains independent of frameworks and external concerns, making our tests more robust and our code more maintainable.","title":"Testing"},{"location":"TESTS/#testing-strategy-for-calibration-service","text":"This document outlines the testing strategy for the Calibration Service, following Clean Architecture principles.","title":"Testing Strategy for Calibration Service"},{"location":"TESTS/#test-structure","text":"The test suite is organized into the following categories: Note: ideally tests/unit should mirror the src folder Unit Tests : Testing individual components in isolation tests/unit/entities : Tests for entity models and validation tests/unit/application : Tests for use cases and business logic tests/unit/infrastructure : Tests for repositories and services tests/unit/interface_adapters : Tests for controllers tests/unit/use_cases : Tests for use cases Integration Tests : Testing the interaction between components tests/integration : API endpoint testing with in-memory repositories End-to-End Tests : Testing the entire system (future implementation) tests/e2e : Full system tests with external dependencies (e.g. live db)","title":"Test Structure"},{"location":"TESTS/#test-dependencies","text":"The test suite uses the following dependencies: pytest : The core testing framework httpx : HTTP client for testing FastAPI endpoints pytest-asyncio : Support for asynchronous tests pytest-cov : Code coverage reporting","title":"Test Dependencies"},{"location":"TESTS/#running-tests","text":"See: README for core tests for this project. Different test scenarios: # Run all tests uv run test # Run with coverage uv run test_cov # Run in test environment PYTHON_ENV=test uv run test Tests can also be run using the run_tests.sh script: bash ./scripts/run_tests.sh [!NOTE] run_tests is executed by pre-commit as a pre-commit hook. More info in Generate coverage reports using the run_tests_with_coverage.sh script: bash ./scripts/run_tests_with_coverage.sh Or, run manually: ```bash # Run all tests PYTHONPATH=./src python -m pytest -v --no-cov # Run unit tests only python -m pytest tests/unit -v --no-cov # Run integration tests only python -m pytest tests/integration -v --no-cov # Run with coverage (pytest.ini passes coverage flags by default) python -m pytest ```","title":"Running Tests"},{"location":"TESTS/#test-data","text":"Unit Tests : Use mock objects and in-memory repositories Integration Tests : Use in-memory repositories for isolation ~~- E2E Tests : Will use test databases or containerized services~~ (future)","title":"Test Data"},{"location":"TESTS/#clean-architecture-testing-approach","text":"Our (ideal) testing follows Clean Architecture principles: Entities Tests : Verify that our core models work correctly Use Case Tests : Ensure business rules are correctly implemented Interface Adapter Tests : Validate controllers and presenters Framework Tests : Test the FastAPI endpoints By following this approach, we can ensure that our business logic remains independent of frameworks and external concerns, making our tests more robust and our code more maintainable.","title":"Clean Architecture Testing Approach"},{"location":"WORKFLOWS/","text":"GitHub Actions Workflows This document explains the GitHub Actions workflows used in the calibration-service project. Overview The project uses GitHub Actions for continuous integration and testing. The workflows are designed to validate code changes, run tests, and ensure the application behaves as expected. All workflows use uv for Python dependency management and virtual environment creation, providing fast and reliable dependency resolution. Workflows 1. CI Workflow ( ci.yaml ) This is the main CI workflow that runs on pushes to main, pull requests, and manual triggers. Jobs: python-tests : Runs Python unit and integration tests with coverage build : Builds the Docker image and uploads it as an artifact container-tests : Tests the Docker image functionality Features: Complete end-to-end testing (in future) Docker image validation Test report generation Code coverage analysis 2. Python Tests Workflow ( pytest.yaml ) This workflow focuses specifically on Python testing and runs when Python files or related configurations change. Jobs: test : Runs Python unit and integration tests with coverage Features: Faster feedback for Python code changes Test report generation Code coverage analysis Path-specific triggering to avoid unnecessary runs 3. Pyright Workflow ( pyright.yaml ) This workflow performs static type checking with Pyright to ensure type safety and catch issues early in development. Configuration is managed in pyproject.toml . Jobs: typecheck : Sets up Python environment with uv, then runs Pyright to check types across the codebase Features: Fast dependency resolution using uv Enforces type-safety/correctness and detects mismatches Catches potential runtime issues during development 4. Ruff Workflow ( ruff.yaml ) This workflow uses the ruff linter and ruff formatter to automatically enforce code quality standards. Ruff is configured via pyproject.toml and runs as a CI job to maintain a clean, consistent codebase. Jobs: ruff : Runs static analysis to enforce formatting, code style, and detect common issues Features: Enforces consistent formatting and PEP 8-style conventions Detects unused code, logic errors, and security concerns Helps catch issues early, before code is merged Test Reports Both the CI Workflow and the Python Tests Workflow generate and upload test reports as artifacts, which can be downloaded from the workflow run page. Running Tests Locally Before submitting a pull request, it's recommended to run the tests locally, or rely on the pre-commit git hook. For detailed information on how to run tests on localhost, see ./TESTS.md . CI/CD Pipeline Flow Code is pushed to GitHub GitHub Actions workflows are triggered: Ruff for linting and formatting Pyright for type checking Python Tests for unit and integration testing CI for complete validation including Docker builds Tests are run and reports are generated If all tests pass, the workflow succeeds Test reports and coverage information are available for review 5. Fly.io Workflow ( deploy_release.yaml ) Deploys container to https://calibration-service.fly.dev Future Enhancements Planned enhancements to the CI/CD pipeline include: Integration with deployment workflows Performance testing Security scanning End-to-end testing with ephemeral containers and/or external services","title":"CICD"},{"location":"WORKFLOWS/#github-actions-workflows","text":"This document explains the GitHub Actions workflows used in the calibration-service project.","title":"GitHub Actions Workflows"},{"location":"WORKFLOWS/#overview","text":"The project uses GitHub Actions for continuous integration and testing. The workflows are designed to validate code changes, run tests, and ensure the application behaves as expected. All workflows use uv for Python dependency management and virtual environment creation, providing fast and reliable dependency resolution.","title":"Overview"},{"location":"WORKFLOWS/#workflows","text":"","title":"Workflows"},{"location":"WORKFLOWS/#1-ci-workflow-ciyaml","text":"This is the main CI workflow that runs on pushes to main, pull requests, and manual triggers. Jobs: python-tests : Runs Python unit and integration tests with coverage build : Builds the Docker image and uploads it as an artifact container-tests : Tests the Docker image functionality Features: Complete end-to-end testing (in future) Docker image validation Test report generation Code coverage analysis","title":"1. CI Workflow (ci.yaml)"},{"location":"WORKFLOWS/#2-python-tests-workflow-pytestyaml","text":"This workflow focuses specifically on Python testing and runs when Python files or related configurations change. Jobs: test : Runs Python unit and integration tests with coverage Features: Faster feedback for Python code changes Test report generation Code coverage analysis Path-specific triggering to avoid unnecessary runs","title":"2. Python Tests Workflow (pytest.yaml)"},{"location":"WORKFLOWS/#3-pyright-workflow-pyrightyaml","text":"This workflow performs static type checking with Pyright to ensure type safety and catch issues early in development. Configuration is managed in pyproject.toml . Jobs: typecheck : Sets up Python environment with uv, then runs Pyright to check types across the codebase Features: Fast dependency resolution using uv Enforces type-safety/correctness and detects mismatches Catches potential runtime issues during development","title":"3. Pyright Workflow (pyright.yaml)"},{"location":"WORKFLOWS/#4-ruff-workflow-ruffyaml","text":"This workflow uses the ruff linter and ruff formatter to automatically enforce code quality standards. Ruff is configured via pyproject.toml and runs as a CI job to maintain a clean, consistent codebase. Jobs: ruff : Runs static analysis to enforce formatting, code style, and detect common issues Features: Enforces consistent formatting and PEP 8-style conventions Detects unused code, logic errors, and security concerns Helps catch issues early, before code is merged","title":"4. Ruff Workflow (ruff.yaml)"},{"location":"WORKFLOWS/#test-reports","text":"Both the CI Workflow and the Python Tests Workflow generate and upload test reports as artifacts, which can be downloaded from the workflow run page.","title":"Test Reports"},{"location":"WORKFLOWS/#running-tests-locally","text":"Before submitting a pull request, it's recommended to run the tests locally, or rely on the pre-commit git hook. For detailed information on how to run tests on localhost, see ./TESTS.md .","title":"Running Tests Locally"},{"location":"WORKFLOWS/#cicd-pipeline-flow","text":"Code is pushed to GitHub GitHub Actions workflows are triggered: Ruff for linting and formatting Pyright for type checking Python Tests for unit and integration testing CI for complete validation including Docker builds Tests are run and reports are generated If all tests pass, the workflow succeeds Test reports and coverage information are available for review","title":"CI/CD Pipeline Flow"},{"location":"WORKFLOWS/#5-flyio-workflow-deploy_releaseyaml","text":"Deploys container to https://calibration-service.fly.dev","title":"5. Fly.io Workflow (deploy_release.yaml)"},{"location":"WORKFLOWS/#future-enhancements","text":"Planned enhancements to the CI/CD pipeline include: Integration with deployment workflows Performance testing Security scanning End-to-end testing with ephemeral containers and/or external services","title":"Future Enhancements"}]}